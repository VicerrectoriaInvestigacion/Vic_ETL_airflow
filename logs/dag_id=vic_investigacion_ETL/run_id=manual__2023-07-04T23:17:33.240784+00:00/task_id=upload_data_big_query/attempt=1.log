[2023-07-04 23:17:36,315] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-07-04T23:17:33.240784+00:00 [queued]>
[2023-07-04 23:17:36,321] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-07-04T23:17:33.240784+00:00 [queued]>
[2023-07-04 23:17:36,322] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-07-04 23:17:36,322] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-07-04 23:17:36,323] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-07-04 23:17:36,330] {taskinstance.py:1397} INFO - Executing <Task(ExportData): upload_data_big_query> on 2023-07-04 23:17:33.240784+00:00
[2023-07-04 23:17:36,335] {standard_task_runner.py:52} INFO - Started process 915 to run task
[2023-07-04 23:17:36,339] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'upload_data_big_query', 'manual__2023-07-04T23:17:33.240784+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmphziiyju9', '--error-file', '/tmp/tmpmy252hfb']
[2023-07-04 23:17:36,343] {standard_task_runner.py:80} INFO - Job 38: Subtask upload_data_big_query
[2023-07-04 23:17:36,395] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-07-04T23:17:33.240784+00:00 [running]> on host f4f0af373b5a
[2023-07-04 23:17:36,446] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=upload_data_big_query
AIRFLOW_CTX_EXECUTION_DATE=2023-07-04T23:17:33.240784+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-07-04T23:17:33.240784+00:00
[2023-07-04 23:17:36,447] {logging_mixin.py:115} INFO - Exporting Data
[2023-07-04 23:17:36,450] {logging_mixin.py:115} INFO - /opt/***/data/to_upload/journals.xlsx
[2023-07-04 23:17:36,450] {logging_mixin.py:115} INFO - FileName: journals
[2023-07-04 23:17:45,655] {logging_mixin.py:115} INFO - LoadJob<project=viceinvestigacion, location=US, id=5865131b-ce5d-42ec-a059-760ed39f6b9d>
[2023-07-04 23:17:45,656] {logging_mixin.py:115} INFO - /opt/***/data/to_upload/produccion_validada.csv
[2023-07-04 23:17:45,657] {logging_mixin.py:115} INFO - FileName: produccion_validada
[2023-07-04 23:17:46,893] {logging_mixin.py:115} INFO - --
[2023-07-04 23:17:46,916] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=upload_data_big_query, execution_date=20230704T231733, start_date=20230704T231736, end_date=20230704T231746
[2023-07-04 23:17:47,048] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-07-04 23:17:47,072] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
