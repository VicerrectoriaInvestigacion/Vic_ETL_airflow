[2023-06-26 12:23:30,388] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-06-26 12:23:30,398] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-06-26 12:23:30,399] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-06-26 12:23:30,400] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-06-26 12:23:30,401] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-06-26 12:23:30,410] {taskinstance.py:1397} INFO - Executing <Task(ExportData): upload_data_big_query> on 2023-04-14 00:00:00+00:00
[2023-06-26 12:23:30,416] {standard_task_runner.py:52} INFO - Started process 2219 to run task
[2023-06-26 12:23:30,421] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'upload_data_big_query', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmp4a_3sdi1', '--error-file', '/tmp/tmp3cnkmywy']
[2023-06-26 12:23:30,424] {standard_task_runner.py:80} INFO - Job 8: Subtask upload_data_big_query
[2023-06-26 12:23:30,504] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [running]> on host ce13f1e72365
[2023-06-26 12:23:30,561] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=upload_data_big_query
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-06-26 12:23:30,564] {logging_mixin.py:115} INFO - Exporting Data
[2023-06-26 12:23:30,567] {logging_mixin.py:115} INFO - /opt/***/data/to_upload/respositorio_inst.xlsx
[2023-06-26 12:23:30,611] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/export_data_operator.py", line 28, in execute
    self.export_data()
  File "/opt/airflow/dags/export_data_operator.py", line 55, in export_data
    df = pd.read_csv(file_path)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 69, in __init__
    self._reader = parsers.TextReader(self.handles.handle, **kwds)
  File "pandas/_libs/parsers.pyx", line 542, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 642, in pandas._libs.parsers.TextReader._get_header
  File "pandas/_libs/parsers.pyx", line 843, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 1917, in pandas._libs.parsers.raise_parser_error
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe7 in position 10: invalid continuation byte
[2023-06-26 12:23:30,623] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=vic_investigacion_ETL, task_id=upload_data_big_query, execution_date=20230414T000000, start_date=20230626T122330, end_date=20230626T122330
[2023-06-26 12:23:30,632] {standard_task_runner.py:97} ERROR - Failed to execute job 8 for task upload_data_big_query ('utf-8' codec can't decode byte 0xe7 in position 10: invalid continuation byte; 2219)
[2023-06-26 12:23:30,674] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-06-26 12:23:30,701] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-07-04 20:58:10,865] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-07-04 20:58:10,870] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-07-04 20:58:10,871] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-07-04 20:58:10,871] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-07-04 20:58:10,872] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-07-04 20:58:10,878] {taskinstance.py:1397} INFO - Executing <Task(ExportData): upload_data_big_query> on 2023-04-14 00:00:00+00:00
[2023-07-04 20:58:10,883] {standard_task_runner.py:52} INFO - Started process 152 to run task
[2023-07-04 20:58:10,886] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'upload_data_big_query', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmpux5nksq9', '--error-file', '/tmp/tmpj829o0ii']
[2023-07-04 20:58:10,888] {standard_task_runner.py:80} INFO - Job 7: Subtask upload_data_big_query
[2023-07-04 20:58:10,938] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.upload_data_big_query scheduled__2023-04-14T00:00:00+00:00 [running]> on host f4f0af373b5a
[2023-07-04 20:58:10,988] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=upload_data_big_query
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-07-04 20:58:10,990] {logging_mixin.py:115} INFO - Exporting Data
[2023-07-04 20:58:10,993] {logging_mixin.py:115} INFO - /opt/***/data/to_upload/journals.xlsx
[2023-07-04 20:58:19,834] {logging_mixin.py:115} INFO - LoadJob<project=viceinvestigacion, location=US, id=d6b372ba-5043-46f3-adaf-33b6408fd3ef>
[2023-07-04 20:58:19,837] {logging_mixin.py:115} INFO - /opt/***/data/to_upload/profesores_validados.csv
[2023-07-04 20:58:23,402] {logging_mixin.py:115} INFO - LoadJob<project=viceinvestigacion, location=US, id=38e73cf5-495e-4dff-81da-32726e7685c4>
[2023-07-04 20:58:23,450] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=upload_data_big_query, execution_date=20230414T000000, start_date=20230704T205810, end_date=20230704T205823
[2023-07-04 20:58:23,562] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-07-04 20:58:23,588] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
