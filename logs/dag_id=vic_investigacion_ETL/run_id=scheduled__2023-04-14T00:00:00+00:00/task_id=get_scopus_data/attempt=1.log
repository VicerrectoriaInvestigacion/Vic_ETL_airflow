[2023-04-14 14:20:26,503] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 14:20:26,512] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 14:20:26,513] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 14:20:26,514] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-04-14 14:20:26,514] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 14:20:26,525] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): get_scopus_data> on 2023-04-14 00:00:00+00:00
[2023-04-14 14:20:26,531] {standard_task_runner.py:52} INFO - Started process 15502 to run task
[2023-04-14 14:20:26,535] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'get_scopus_data', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/scopus_operator.py', '--cfg-path', '/tmp/tmpmaut9nth', '--error-file', '/tmp/tmpgzoj30al']
[2023-04-14 14:20:26,538] {standard_task_runner.py:80} INFO - Job 21: Subtask get_scopus_data
[2023-04-14 14:20:26,606] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [running]> on host 470baecc07a1
[2023-04-14 14:20:26,665] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=get_scopus_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-04-14 14:20:26,667] {logging_mixin.py:115} INFO - Hello people from python funtion
[2023-04-14 14:20:26,669] {python.py:173} INFO - Done. Returned value was: None
[2023-04-14 14:20:26,685] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=get_scopus_data, execution_date=20230414T000000, start_date=20230414T142026, end_date=20230414T142026
[2023-04-14 14:20:26,713] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-04-14 14:20:26,752] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-04-14 16:17:00,742] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:17:00,750] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:17:00,752] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:17:00,753] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-04-14 16:17:00,754] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:17:00,764] {taskinstance.py:1397} INFO - Executing <Task(ReadScopus): get_scopus_data> on 2023-04-14 00:00:00+00:00
[2023-04-14 16:17:00,771] {standard_task_runner.py:52} INFO - Started process 258 to run task
[2023-04-14 16:17:00,775] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'get_scopus_data', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '47', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmpv7vtpzc3', '--error-file', '/tmp/tmppd05dk4c']
[2023-04-14 16:17:00,779] {standard_task_runner.py:80} INFO - Job 47: Subtask get_scopus_data
[2023-04-14 16:17:00,880] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [running]> on host c91627f658c0
[2023-04-14 16:17:00,966] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=get_scopus_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-04-14 16:17:00,971] {logging_mixin.py:115} INFO - Getting Scopus Data
[2023-04-14 16:17:00,973] {logging_mixin.py:115} INFO - The api key is:  640ababb3eaaa3723c7cc11be848250b
[2023-04-14 16:17:00,979] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/read_scopus_operator.py", line 27, in execute
    self.saveData()
  File "/opt/airflow/dags/read_scopus_operator.py", line 30, in saveData
    authors_ids_data= pd.read_excel("authors_ids/authors_ids.xlsx")
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 364, in read_excel
    io = ExcelFile(io, storage_options=storage_options, engine=engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 1192, in __init__
    content_or_path=path_or_buffer, storage_options=storage_options
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 1071, in inspect_excel_format
    content_or_path, "rb", storage_options=storage_options, is_text=False
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 711, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: 'authors_ids/authors_ids.xlsx'
[2023-04-14 16:17:00,998] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=vic_investigacion_ETL, task_id=get_scopus_data, execution_date=20230414T000000, start_date=20230414T161700, end_date=20230414T161700
[2023-04-14 16:17:01,009] {standard_task_runner.py:97} ERROR - Failed to execute job 47 for task get_scopus_data ([Errno 2] No such file or directory: 'authors_ids/authors_ids.xlsx'; 258)
[2023-04-14 16:17:01,029] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-04-14 16:17:01,066] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-04-14 16:39:37,523] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:39:37,531] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:39:37,532] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:39:37,532] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-04-14 16:39:37,533] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:39:37,541] {taskinstance.py:1397} INFO - Executing <Task(ReadScopus): get_scopus_data> on 2023-04-14 00:00:00+00:00
[2023-04-14 16:39:37,547] {standard_task_runner.py:52} INFO - Started process 94 to run task
[2023-04-14 16:39:37,551] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'get_scopus_data', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmppdowwxer', '--error-file', '/tmp/tmp9fzlgqcc']
[2023-04-14 16:39:37,553] {standard_task_runner.py:80} INFO - Job 54: Subtask get_scopus_data
[2023-04-14 16:39:37,629] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [running]> on host d1b5acf00b55
[2023-04-14 16:39:37,707] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=get_scopus_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-04-14 16:39:37,710] {logging_mixin.py:115} INFO - Getting Scopus Data
[2023-04-14 16:39:37,711] {logging_mixin.py:115} INFO - The api key is:  640ababb3eaaa3723c7cc11be848250b
[2023-04-14 16:39:37,711] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/read_scopus_operator.py", line 27, in execute
    self.saveData()
  File "/opt/airflow/dags/read_scopus_operator.py", line 30, in saveData
    with open("authors_ids/authors_ids.xlsx", "r") as file:
FileNotFoundError: [Errno 2] No such file or directory: 'authors_ids/authors_ids.xlsx'
[2023-04-14 16:39:37,726] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=vic_investigacion_ETL, task_id=get_scopus_data, execution_date=20230414T000000, start_date=20230414T163937, end_date=20230414T163937
[2023-04-14 16:39:37,740] {standard_task_runner.py:97} ERROR - Failed to execute job 54 for task get_scopus_data ([Errno 2] No such file or directory: 'authors_ids/authors_ids.xlsx'; 94)
[2023-04-14 16:39:37,764] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-04-14 16:39:37,801] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-04-14 16:55:52,149] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:55:52,155] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-04-14 16:55:52,156] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:55:52,156] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-04-14 16:55:52,157] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-04-14 16:55:52,166] {taskinstance.py:1397} INFO - Executing <Task(ReadScopus): get_scopus_data> on 2023-04-14 00:00:00+00:00
[2023-04-14 16:55:52,175] {standard_task_runner.py:52} INFO - Started process 86 to run task
[2023-04-14 16:55:52,179] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'get_scopus_data', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmpla29chqu', '--error-file', '/tmp/tmpm02gcq65']
[2023-04-14 16:55:52,180] {standard_task_runner.py:80} INFO - Job 64: Subtask get_scopus_data
[2023-04-14 16:55:52,237] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [running]> on host 51874f25fd7b
[2023-04-14 16:55:52,296] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=get_scopus_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-04-14 16:55:52,298] {logging_mixin.py:115} INFO - Getting Scopus Data
[2023-04-14 16:55:52,298] {logging_mixin.py:115} INFO - The api key is:  640ababb3eaaa3723c7cc11be848250b
[2023-04-14 16:55:52,299] {logging_mixin.py:115} INFO - READIINGGGGGGGGGGG!!!!
[2023-04-14 16:55:52,313] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=get_scopus_data, execution_date=20230414T000000, start_date=20230414T165552, end_date=20230414T165552
[2023-04-14 16:55:52,351] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-04-14 16:55:52,382] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-31 23:29:31,596] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-05-31 23:29:31,603] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [queued]>
[2023-05-31 23:29:31,605] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-05-31 23:29:31,605] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-05-31 23:29:31,606] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-05-31 23:29:31,614] {taskinstance.py:1397} INFO - Executing <Task(ReadScopus): get_scopus_data> on 2023-04-14 00:00:00+00:00
[2023-05-31 23:29:31,620] {standard_task_runner.py:52} INFO - Started process 124 to run task
[2023-05-31 23:29:31,625] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'get_scopus_data', 'scheduled__2023-04-14T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmp3rb0t396', '--error-file', '/tmp/tmpv60oy03l']
[2023-05-31 23:29:31,627] {standard_task_runner.py:80} INFO - Job 3: Subtask get_scopus_data
[2023-05-31 23:29:31,718] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.get_scopus_data scheduled__2023-04-14T00:00:00+00:00 [running]> on host 5d9ccb732815
[2023-05-31 23:29:31,791] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=get_scopus_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-14T00:00:00+00:00
[2023-05-31 23:29:31,792] {logging_mixin.py:115} INFO - Getting Scopus Data
[2023-05-31 23:29:31,793] {logging_mixin.py:115} INFO - The api key is:  640ababb3eaaa3723c7cc11be848250b
[2023-05-31 23:29:31,793] {logging_mixin.py:115} INFO - DAG PATH:  /opt/***
[2023-05-31 23:29:32,183] {logging_mixin.py:115} INFO -        Cedula                            Nombre    Scopus_ID
0  52390079.0       Pomares Quimbaya Alexandra   24832026300
1         NaN       Carlos Andres Parra Acevedo  57212998692
2  39785999.0          Burbano Valente, Johanna  20436581100
3  10141825.0       Santacoloma Giraldo, Andres  24462330500
4  52704428.0  Garcia Padilla, Dennys del Rocio  13403648000
5  52772896.0        Rubio Leon, Diana Carolina  56491243500
[2023-05-31 23:29:32,185] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/24832026300
[2023-05-31 23:29:33,061] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/24832026300
[2023-05-31 23:29:34,067] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2824832026300%29
[2023-05-31 23:29:35,425] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:36,422] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/57212998692
[2023-05-31 23:29:37,069] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/57212998692
[2023-05-31 23:29:38,068] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2857212998692%29
[2023-05-31 23:29:39,332] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:40,328] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/20436581100
[2023-05-31 23:29:40,932] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/20436581100
[2023-05-31 23:29:41,932] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2820436581100%29
[2023-05-31 23:29:42,911] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:43,914] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/24462330500
[2023-05-31 23:29:44,534] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/24462330500
[2023-05-31 23:29:45,536] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2824462330500%29
[2023-05-31 23:29:46,581] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:47,582] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/13403648000
[2023-05-31 23:29:49,054] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/13403648000
[2023-05-31 23:29:50,059] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2813403648000%29
[2023-05-31 23:29:51,193] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:52,192] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/author/author_id/56491243500
[2023-05-31 23:29:52,830] {elsentity.py:77} INFO - Data loaded for https://api.elsevier.com/content/author/author_id/56491243500
[2023-05-31 23:29:53,830] {elsclient.py:109} INFO - Sending GET request to https://api.elsevier.com/content/search/scopus?query=AU-ID%2856491243500%29
[2023-05-31 23:29:55,003] {utils.py:41} INFO - Converting prism:coverDate
[2023-05-31 23:29:55,035] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=get_scopus_data, execution_date=20230414T000000, start_date=20230531T232931, end_date=20230531T232955
[2023-05-31 23:29:55,102] {local_task_job.py:156} INFO - Task exited with return code 0
