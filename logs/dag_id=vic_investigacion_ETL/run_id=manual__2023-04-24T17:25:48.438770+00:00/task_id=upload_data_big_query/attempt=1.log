[2023-04-24 17:25:55,641] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-04-24T17:25:48.438770+00:00 [queued]>
[2023-04-24 17:25:55,648] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-04-24T17:25:48.438770+00:00 [queued]>
[2023-04-24 17:25:55,649] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-04-24 17:25:55,650] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-04-24 17:25:55,650] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-04-24 17:25:55,663] {taskinstance.py:1397} INFO - Executing <Task(ExportData): upload_data_big_query> on 2023-04-24 17:25:48.438770+00:00
[2023-04-24 17:25:55,669] {standard_task_runner.py:52} INFO - Started process 6131 to run task
[2023-04-24 17:25:55,673] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'vic_investigacion_ETL', 'upload_data_big_query', 'manual__2023-04-24T17:25:48.438770+00:00', '--job-id', '401', '--raw', '--subdir', 'DAGS_FOLDER/vic_investigacion_dag.py', '--cfg-path', '/tmp/tmply51lle1', '--error-file', '/tmp/tmp0omm606s']
[2023-04-24 17:25:55,676] {standard_task_runner.py:80} INFO - Job 401: Subtask upload_data_big_query
[2023-04-24 17:25:55,750] {task_command.py:371} INFO - Running <TaskInstance: vic_investigacion_ETL.upload_data_big_query manual__2023-04-24T17:25:48.438770+00:00 [running]> on host b136a0a45498
[2023-04-24 17:25:55,807] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=vic_investigacion_ETL
AIRFLOW_CTX_TASK_ID=upload_data_big_query
AIRFLOW_CTX_EXECUTION_DATE=2023-04-24T17:25:48.438770+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-04-24T17:25:48.438770+00:00
[2023-04-24 17:25:55,809] {logging_mixin.py:115} INFO - Exporting Data
[2023-04-24 17:25:55,982] {logging_mixin.py:115} INFO - Scopus_id          int64
orcid             object
document_count     int64
cited_by_count     int64
citation_count     int64
pick_date         object
dtype: object
[2023-04-24 17:26:00,825] {logging_mixin.py:115} INFO - LoadJob<project=viceinvestigacion, location=US, id=74d661a1-cb0a-4d96-a6d3-cda3477437c1>
[2023-04-24 17:26:00,839] {logging_mixin.py:115} INFO - Scopus_id                        int64
orcid                           object
document_count                   int64
cited_by_count                   int64
citation_count                   int64
pick_date                       object
Current_affil_status            object
Current_affil_affiliation_id     int64
Current_affil_relationship      object
Current_affil_afdispname        object
Current_affil_day                int64
Current_affil_month              int64
Current_affil_timestamp         object
Current_affil_year               int64
Current_affil_city              object
Current_affil_postal_code        int64
Current_affil_country           object
dtype: object
[2023-04-24 17:26:06,260] {logging_mixin.py:115} INFO - LoadJob<project=viceinvestigacion, location=US, id=678e7e46-6d4f-45bb-9230-d39e79ad8b35>
[2023-04-24 17:26:06,368] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=vic_investigacion_ETL, task_id=upload_data_big_query, execution_date=20230424T172548, start_date=20230424T172555, end_date=20230424T172606
[2023-04-24 17:26:06,703] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-04-24 17:26:06,775] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
